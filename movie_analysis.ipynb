{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49e9c70a",
   "metadata": {},
   "source": [
    "## Movies Reviews Text Based Analysis & Classification Project\n",
    "ADS509 - Team 3 - Final Group Project<p>\n",
    "Jacqueline Vo, Connie Chow<p>\n",
    "October 23, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2f15d7",
   "metadata": {},
   "source": [
    "### Load the Movie Reviews Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591c460b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyLDAvis.lda_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28708/3999078394.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Topic Modeling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNMF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis.lda_model'"
     ]
    }
   ],
   "source": [
    "# Data Manipulation and Analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "import emoji\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "# Text Feature Extraction and NLP Models\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "# ML Models and Tools\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Topic Modeling\n",
    "import pyLDAvis.lda_model\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "\n",
    "# Additional Libraries\n",
    "from collections import Counter\n",
    "\n",
    "# Install packages if needed\n",
    "#spacy.cli.download('en_core_web_sm')\n",
    "#nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06456cf1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50ea2f42",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52055540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL\n",
    "url = \"https://raw.githubusercontent.com/jvo024/ads509-movie-scrape/main/datasets/all_tmbd_rt_data.csv\"\n",
    "\n",
    "# Read data from the URL into a DataFrame\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the DataFrame (optional)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b241afd9",
   "metadata": {},
   "source": [
    "### Text Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91edcd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "PUNCTUATION = set(punctuation)\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "def descriptive_stats(tokens, top_tokens=10, verbose=True):\n",
    "    \"\"\"\n",
    "    Calculate descriptive statistics for a list of tokens.\n",
    "    Args:\n",
    "        tokens (list): List of tokens.\n",
    "        top_tokens (int): Number of top tokens to display.\n",
    "        verbose (bool): Print statistics if True.\n",
    "    Returns:\n",
    "        list: A list containing [num_tokens, num_unique_tokens, lexical_diversity, num_characters]\n",
    "    \"\"\"\n",
    "    num_tokens = len(tokens)\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    lexical_diversity = num_unique_tokens / num_tokens\n",
    "    num_characters = sum(len(token) for token in tokens)\n",
    "    token_counter = Counter(tokens)\n",
    "    most_common_tokens = token_counter.most_common(top_tokens)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Number of tokens: {num_tokens}\")\n",
    "        print(f\"Number of unique tokens: {num_unique_tokens}\")\n",
    "        print(f\"Number of characters: {num_characters}\")\n",
    "        print(f\"Lexical diversity: {lexical_diversity:.3f}\")\n",
    "        print(f\"Most common tokens (Top {top_tokens}):\")\n",
    "        for token, count in most_common_tokens:\n",
    "            print(f\" - {token}: {count}\")\n",
    "\n",
    "    return [num_tokens, num_unique_tokens, lexical_diversity, num_characters]\n",
    "\n",
    "def remove_hyperlink(text):\n",
    "    \"\"\"\n",
    "    Remove hyperlinks from text using regular expressions.\n",
    "    \"\"\"\n",
    "    hyperlink_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    cleaned_text = re.sub(hyperlink_pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stop(tokens):\n",
    "    \"\"\"\n",
    "    Remove stopwords from a list of tokens.\n",
    "    \"\"\"\n",
    "    removed_tokens = [token for token in tokens if token.lower() not in STOPWORDS and token != 'nan']\n",
    "    return removed_tokens\n",
    "\n",
    "def remove_numerical(tokens):\n",
    "    \"\"\"\n",
    "    Remove tokens that are purely numerical.\n",
    "    \"\"\"\n",
    "    cleaned_tokens = [token for token in tokens if not re.match(r'^[0-9.]+$', token)]\n",
    "    return cleaned_tokens\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    Remove punctuation from text.\n",
    "    \"\"\"\n",
    "    if text == 'nan':\n",
    "        return ''  # Remove 'nan'\n",
    "\n",
    "    PUNCTUATION.add(\"'\")\n",
    "    return \"\".join([ch for ch in text if ch not in PUNCTUATION])\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize text.\n",
    "    \"\"\"\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def prepare(text, pipeline):\n",
    "    \"\"\"\n",
    "    Apply a list of text processing transformations to a text.\n",
    "    \"\"\"\n",
    "    tokens = str(text)\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "all_language_emojis = set()\n",
    "\n",
    "for country in emoji.EMOJI_DATA:\n",
    "    for em in emoji.EMOJI_DATA[country]:\n",
    "        all_language_emojis.add(em)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [remove_hyperlink, str.lower, remove_punctuation, tokenize, remove_stop, remove_numerical]\n",
    "\n",
    "df[\"tokens\"] = df[\"review_content\"].apply(prepare, pipeline=pipeline)\n",
    "df[\"num_tokens\"] = df[\"tokens\"].map(len)\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460c1f74",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "A pipeline was applied to remove hyperlinks, punctuation, stopwords, numbers, in addition to converting all words into lowercase, and tokenizing review_content. For additional analysis, the total number of tokens were counted for each movie review given.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def9333f",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e81cf",
   "metadata": {},
   "source": [
    "#### Descriptive Statistics for Good and Bad Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e0470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing split to view dataset in good/bad\n",
    "good_df = df[df['sentiment'] == 'good']\n",
    "bad_df = df[df['sentiment'] == 'bad']\n",
    "\n",
    "# Combine all tokens\n",
    "good_tokens = good_df[\"tokens\"].sum()\n",
    "bad_tokens = bad_df[\"tokens\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b550db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use descriptive stats function on both datasets\n",
    "print(f\"--- Good Reviews ---\")\n",
    "good_stats = descriptive_stats(good_tokens)\n",
    "print(f\"--- Bad Reviews ---\")\n",
    "bad_stats = descriptive_stats(bad_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8ed6e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Just to note, we are aware of the apostrophe showing up as a top token.  After some research, we concluded that the tokenization needs to be done using spacy package which can process contraction words.  For example, a token like \"I'm\" can be broken up into I and am.  This was one step further that will be explored with the project Next Steps.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623be4f",
   "metadata": {},
   "source": [
    "#### Token Concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edbec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count total number of tokens for both dataframes\n",
    "total_good = good_stats[0]\n",
    "total_bad = bad_stats[0]\n",
    "\n",
    "token_counts_good = Counter(good_tokens)\n",
    "token_counts_bad = Counter(bad_tokens)\n",
    "\n",
    "# Create dataframe to label the token, and number of times it appears for both good/bad\n",
    "good_df = pd.DataFrame(token_counts_good.items(), columns=[\"token\", \"good_tokens\"])\n",
    "bad_df = pd.DataFrame(token_counts_bad.items(), columns=[\"token\", \"bad_tokens\"])\n",
    "\n",
    "# Calculate the concentration for good/bad tokens\n",
    "good_df[\"good concentration\"] = good_df.apply(lambda row: row[\"good_tokens\"] / total_good, axis=1)\n",
    "bad_df[\"bad concentration\"] = bad_df.apply(lambda row: row[\"bad_tokens\"] / total_bad, axis=1)\n",
    "\n",
    "calc_df = [good_df, bad_df]\n",
    "\n",
    "group_df = calc_df[0]\n",
    "\n",
    "\n",
    "for calc_df in calc_df[1:]:\n",
    "\n",
    "    group_df = pd.merge(group_df, calc_df, on=\"token\", how=\"inner\")\n",
    "\n",
    "cutoff = 5\n",
    "\n",
    "def check_cutoff(row):\n",
    "    \"\"\"\n",
    "    Verify that this token appears in good_df and bad_df above the specified cut-off\n",
    "    \"\"\"\n",
    "    return (row['good_tokens'] > cutoff) and (row['bad_tokens'] > cutoff)\n",
    "\n",
    "group_df['cutoff'] = group_df.apply(check_cutoff, axis=1)\n",
    "group_df['ratio'] = group_df[\"good_tokens\"] / group_df[\"bad_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f426d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify tokens with largest ratio of good:bad\n",
    "top_10 = group_df[group_df['cutoff'] == True].sort_values(by='ratio', ascending=False).head(10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a018206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify tokens with smallest ratio of good:bad\n",
    "bottom_10 = group_df[group_df['cutoff'] == True].sort_values(by='ratio', ascending=False).tail(10)\n",
    "bottom_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d935be",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "We explored if certain tokens were more common based on the sentiment of the review. A cutoff was set so that this token would need to appear more times than the specified cut-off. In this case, it would need to appear in good_tokens and bad_tokens greater than 5 times. It appears that there are clear positive and negative connotations for certain tokens, however there are also tokens that might seem out of context such as caleb, guadgnino, and steppewolf.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10691b",
   "metadata": {},
   "source": [
    "#### Word Clouds: Tokens from Bad Reviews Word Cloud & Good Review Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f929724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def count_words(df, column='token', preprocess=None, min_freq=2):\n",
    "    \"\"\"\"\n",
    "    Process tokens and update counter\n",
    "    \"\"\"\n",
    "    def update(doc):\n",
    "        tokens = doc if preprocess is None else preprocess(doc)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    # create counter and run through all data\n",
    "    counter = Counter()\n",
    "    df[column].map(update)\n",
    "\n",
    "    # transform counter into data frame\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "    freq_df = freq_df.query('freq >= @min_freq')\n",
    "    freq_df.index.name = 'token'\n",
    "\n",
    "    return freq_df.sort_values('freq', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f74f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(tokens, title, width=800, height=400, background_color=\"white\"):\n",
    "\n",
    "    wordcloud = WordCloud(width=width, height=height, background_color=background_color).generate_from_frequencies(tokens)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create word clouds for good_tokens and bad_tokens\n",
    "good_word_counts = Counter(good_tokens)\n",
    "bad_word_counts = Counter(bad_tokens)\n",
    "\n",
    "generate_wordcloud(good_word_counts, \"Word Cloud for Good Tokens\")\n",
    "generate_wordcloud(bad_word_counts, \"Word Cloud for Bad Tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7c395",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Both the good and bad sentiment wordclouds appear fairly generic in terms of most frequent words. There are no extremely polarizing tokens that might outwardly indicate a specific sentiment on its own. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e1df2",
   "metadata": {},
   "source": [
    "#### The most common two word phrases for good and bad reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_bigram(corpus, n):\n",
    "\n",
    "    vec = CountVectorizer(ngram_range=(2,2)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "common_words = get_top_n_bigram(df['review_content'], 30)\n",
    "df2 = pd.DataFrame(common_words, columns=['Text', \"Count\"])\n",
    "\n",
    "df2.groupby('Text').sum()['Count'].sort_values(ascending=False).plot(\n",
    "kind='bar',\n",
    "figsize=(12,6),\n",
    "xlabel = \"Bigram Words\",\n",
    "ylabel = \"Count\",\n",
    "title = \"Bar chart of Bigrams Frequency\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb78be51",
   "metadata": {},
   "source": [
    "### Train Test Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = df[['tokens', 'sentiment']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cutoff = 10\n",
    "\n",
    "tokens = [word for text, _ in movie_reviews for word in text]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e637fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"This function takes in the movie review text and list of\n",
    "    feature words (from above) and marks each word in the review\n",
    "    as either existing in the feature word list as True or False\n",
    "    This will be fed as training data to the classifier\n",
    "    \"\"\"\n",
    "\n",
    "    ret_dict = dict()\n",
    "\n",
    "    words = text.split()\n",
    "   \n",
    "    # Iterate through the words in the text\n",
    "    for word in words:\n",
    "        # Check if the word is in the list of words fw\n",
    "        if word in fw:\n",
    "            # If it is in fw, set its value to True in the features dictionary\n",
    "            ret_dict[word] = True\n",
    "            \n",
    "    return {k: v for k, v in ret_dict.items() if v}\n",
    "    \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fdd70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(' '.join(tokens), feature_words), sentiment)\n",
    "               for (tokens, sentiment) in movie_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0751cc5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> The features here will be used for the upcoming modeling phase. This will create a list of lists, where each list is a review with a list of tokens, in addition to the sentiment of the review. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e44c9ec",
   "metadata": {},
   "source": [
    "### Modeling & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f591fe4d",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c2e45",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> [Naive Bayes is the classification model typically used for text based analysis and sentiment analysis.  It is a quick algorithm and can pickup the feature set even with a small a dataset.  It also assumes independence between feature words, allowing each token to have equal weight] </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7418b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 500\n",
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"Accuracy Score: \", nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecc7155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most informative features (tokens)\n",
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd1fb8",
   "metadata": {},
   "source": [
    "#### LinearSVC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacd3e4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> [SVM generalizes well in high dimensional spaces like those corresponding to texts.  This algorithm eliminates the need for feature selection which makes its application to text analysis much easier.] </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236f8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df['review_content']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "freq_vector = CountVectorizer(stop_words=\"english\")\n",
    "X_train_freq = freq_vector.fit_transform(X_train)\n",
    "X_train_freq.shape\n",
    "\n",
    "tfidf_transf = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transf.fit_transform(X_train_freq)\n",
    "X_train_tfidf.shape\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_test_freq = freq_vector.transform(X_test)\n",
    "X_test_tfidf = tfidf_transf.transform(X_test_freq)\n",
    "y_pred = svc.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8114d",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e00f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform the Input Text of Training Data using Trained Tfidf Vectorizer\n",
    "# train_feature_vectors = count_text_vectorizer.transform(X_train)\n",
    "# #train_feature_vectors = train_feature_vectors.todense()\n",
    "#\n",
    "# # Get the name of Features (Feature Set) and create a DataFrame of Input Features\n",
    "# input_training_features = pd.DataFrame(train_feature_vectors, columns = count_text_vectorizer.get_feature_names())\n",
    "# input_training_features = input_training_features.round(2)\n",
    "#\n",
    "# # Display the Document Feature Matrix of Training Data\n",
    "# print(\"Document Features Matrix of Training Data :\")\n",
    "# print(\"============================================\")\n",
    "# #input_training_features = input_training_features.round(2)\n",
    "# input_training_features.head()\n",
    "#\n",
    "# # Split the Training Data Outputs / Labels and Create a DataFrame\n",
    "# training_data_output = pd.DataFrame(y_train)\n",
    "#\n",
    "# # Output Label Gender of Training Data\n",
    "# print(\"Output of Training Data:\")\n",
    "# print(\"========================\")\n",
    "# training_data_output.head()\n",
    "#\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# # Initialize the LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "#\n",
    "# # Fit and transform the 'Sentiment' column\n",
    "# training_data_output['sentiment'] = label_encoder.fit_transform(y_train)\n",
    "#\n",
    "# from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# X = input_training_features\n",
    "# y = training_data_output\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2020)\n",
    "#\n",
    "# random_forest_classifier = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "# random_forest = random_forest_classifier.fit(X_train,np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform the Input Text of Training Data using Trained Tfidf Vectorizer\n",
    "# count_vectorizer = CountVectorizer(stop_words = \"english\")\n",
    "# count_vectorizer = count_vectorizer.fit(X_train['review_content'])\n",
    "# train_feature_vectors = count_vectorizer.transform(df_reviews['review_content'])\n",
    "# train_feature_vectors = train_feature_vectors.todense()\n",
    "#\n",
    "# # Get the name of Features (Feature Set) and create a DataFrame of Input Features\n",
    "# input_training_features = pd.DataFrame(train_feature_vectors, columns = count_vectorizer.get_feature_names())\n",
    "# input_training_features = input_training_features.round(2)\n",
    "#\n",
    "# training_data_output = pd.DataFrame(df_reviews['sentiment'])\n",
    "# #training_data_output['sentiment'] = label_encoder.fit_transform(training_data_output['sentiment'])\n",
    "#\n",
    "# X = input_training_features\n",
    "# y = training_data_output\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484bdb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "#\n",
    "# random_forest_classifier = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "# random_forest = random_forest_classifier.fit(X_train,np.ravel(y_train))\n",
    "#\n",
    "# print(\"Parameters and their values:\")\n",
    "# print(\"============================\")\n",
    "# print(random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# print(metrics.confusion_matrix(y_test, predictions))\n",
    "# print(metrics.classification_report(y_test, predictions))\n",
    "# print(metrics.accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5b142f",
   "metadata": {},
   "source": [
    "### Topic Modeling - LSA, LDA, NMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023785b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_text_vectorizer = CountVectorizer(stop_words=STOPWORDS, min_df=5, max_df=0.7)\n",
    "count_text_vectors = count_text_vectorizer.fit_transform(df['review_content'])\n",
    "\n",
    "tfidf_text_vectorizer = TfidfVectorizer(stop_words=STOPWORDS, min_df=5, max_df=0.7)\n",
    "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(df['review_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581b30d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def display_topics(model, features, no_top_words=15):\n",
    "    \"\"\"\n",
    "    This will take into the corresponding model, and\n",
    "    output the top words, in addition to how strong of\n",
    "    a match it is to the topic.\n",
    "    \"\"\"\n",
    "\n",
    "    for topic, words in enumerate(model.components_):\n",
    "\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6db48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_text_vectorizer = CountVectorizer(stop_words=STOPWORDS, min_df=5, max_df=0.7)\n",
    "count_text_vectors = count_text_vectorizer.fit_transform(df['review_content'])\n",
    "\n",
    "tfidf_text_vectorizer = TfidfVectorizer(stop_words=STOPWORDS, min_df=5, max_df=0.7)\n",
    "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(df['review_content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32df6cf",
   "metadata": {},
   "source": [
    "#### Non-Negative Matrix Factorization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_text_model = NMF(n_components=2, random_state=314)\n",
    "W_text_matrix = nmf_text_model.fit_transform(tfidf_text_vectors)\n",
    "H_text_matrix = nmf_text_model.components_\n",
    "\n",
    "display_topics(nmf_text_model, tfidf_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49341b14",
   "metadata": {},
   "source": [
    "#### LSA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fbc25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_para_model = TruncatedSVD(n_components=2, random_state=509)\n",
    "W_svd_para_matrix = svd_para_model.fit_transform(tfidf_text_vectors)\n",
    "H_svd_para_matrix = svd_para_model.components_\n",
    "\n",
    "display_topics(svd_para_model, tfidf_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44917748",
   "metadata": {},
   "source": [
    "#### LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bb368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_para_model = LatentDirichletAllocation(n_components=2, random_state=509)\n",
    "W_lda_para_matrix = lda_para_model.fit_transform(count_text_vectors)\n",
    "H_lda_para_matrix = lda_para_model.components_\n",
    "\n",
    "display_topics(lda_para_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a27e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_display = pyLDAvis.lda_model.prepare(lda_para_model, count_text_vectors,\n",
    "                                         count_text_vectorizer, sort_topics=False)\n",
    "\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f6a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import categories\n",
    "\n",
    "def most_common_category(df, topic_idx):\n",
    "    \"\"\"\n",
    "    Filter the dataframe based on the sentiment\n",
    "    (good/bad) then identify what sentiment the\n",
    "    topic is most likely to be.\n",
    "    \"\"\"\n",
    "    topic_categories = df[df['sentiment'] == unique_categories[topic_idx]]['sentiment']\n",
    "    return topic_categories.mode().iloc[0]\n",
    "\n",
    "models = [nmf_text_model, svd_para_model, lda_para_model]\n",
    "\n",
    "# Get the unique sentiment categories from the dataframe\n",
    "unique_categories = df['sentiment'].unique()\n",
    "\n",
    "for model in models:\n",
    "    matches = {i: most_common_category(df, i) for i in range(model.n_components)}\n",
    "\n",
    "    for i, matched_category in matches.items():\n",
    "        print(f\"Model: {model.__class__.__name__}, Topic {i} - '{matched_category}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a708c",
   "metadata": {},
   "source": [
    "All three models had similar results, and identified Topic 0 to have a good sentiment, and Topic 1 to have a bad sentiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
